{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "uLR90WhedwER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Transfer Learning and Fine-tuning: Background"
      ],
      "metadata": {
        "id": "bKim3KwyTp11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problems with training our own model\n",
        "    - Deep Learning is very costly since it requires\n",
        "        - lots of data\n",
        "        - lots of time for training\n",
        "        - lots of GPU compute\n",
        "    - No specific way to get best performing model for our dataset\n",
        "\n",
        "        Ambiguity with regards to\n",
        "        - Which kernel size to take ?\n",
        "        - How many kernels per layer ?\n",
        "        - How many layers ?\n",
        "        - Which activation to use ?\n",
        "\n",
        "- Solution:\n",
        "    \n",
        "    - Scientists did a lot of experiments with lots of data and with lots of hyperparameter choices (kernel size, no of kernels, no of layers, activation etc.) and came up with Deep Learning models that have very high accuracy on gigantic datasets.\n",
        "\n",
        "    - ILSVRC (ImageNet Large Scale Visual Recognition Challenge):\n",
        "        - ImageNet dataset has 1.4 Million images in 1000 classes\n",
        "        - Build a Deep Learning model that has the most accuracy on ImageNet dataset\n",
        "\n",
        "    - If this Deep Learning model performs really well in a gigantic dataset like ImageNet with more no of images and more no of classes, why can't we use this for our dataset (of course with less no of images and less no of classes) ?"
      ],
      "metadata": {
        "id": "hVH5PreNCXzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning as subset of ML\n",
        "\n",
        "from IPython import display\n",
        "display.Image(\"data/images/DL_01_Intro-01-DL-subset-of-ML.jpg\")"
      ],
      "metadata": {
        "id": "juNAxVBFg7sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "qqv0L0R9dyKJ"
      }
    }
  ]
}