{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "uLR90WhedwER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction"
      ],
      "metadata": {
        "id": "bKim3KwyTp11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have seen that Sliding Window Technique is computationally expensive and inefficient due to the very high number of bounding box positions. Hence, in order to speed up the object detection, we have two options:\n",
        "\n",
        "1. Use a shallow network with less no of parameters $\\implies$ CNN model may not perform well\n",
        "2. Reduce the no of bounding boxes\n",
        "    - No need to pass bounding boxes with \"Background\" class (since CNN do not learn anything)\n",
        "    - No need for duplicate bounding boxes for same object\n",
        "\n",
        "**RCNN (Regions with Convolutional Neural Networks)** tries to get only the regions of image in which there is a high probability of an object. Thus, RCNN reduces the no of regions that we pass into the CNN."
      ],
      "metadata": {
        "id": "yysQJ_xfx_px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "Wh40a2VxMc3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Object Detection with RCNN"
      ],
      "metadata": {
        "id": "RIicKTK-Mc34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-CNN (Regions with Convolutional Neural Networks) is a pioneering deep learning method for object detection that was introduced by Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik in 2014. It brought significant improvements to object detection by combining region proposals with Convolutional Neural Networks (CNNs). The main idea is to generate region proposals, use a CNN to extract features from each proposal, and then classify these features into object categories or background."
      ],
      "metadata": {
        "id": "fvalrpzUMq2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Steps in R-CNN"
      ],
      "metadata": {
        "id": "u6rvieGmNZJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Region Proposal Generation:**\n",
        "\n",
        "    - **Selective Search:** R-CNN uses a region proposal algorithm called Selective Search to generate around 2000 region proposals (bounding boxes) from an input image. Selective Search combines the advantages of both exhaustive search and segmentation to find regions that are likely to contain objects.\n",
        "\n",
        "2. **Feature Extraction:**\n",
        "\n",
        "    - Each of the 2000 region proposals is then warped into a fixed-size (e.g., 227x227) image patch.\n",
        "    - These patches are fed into a pre-trained CNN (like AlexNet) to extract a fixed-length feature vector for each region. The CNN acts as a feature extractor.\n",
        "\n",
        "3. **Classification:**\n",
        "\n",
        "    - The extracted features are then passed to a set of class-specific linear SVMs (Support Vector Machines) to classify each region proposal into one of the object classes or background (non-object).\n",
        "\n",
        "4. **Bounding Box Regression:**\n",
        "\n",
        "    - To refine the bounding box coordinates, a bounding box regressor is trained to predict more accurate bounding boxes for each region proposal. This step improves the localization accuracy of the detected objects."
      ],
      "metadata": {
        "id": "Es1alXhzNW_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Detailed Workflow"
      ],
      "metadata": {
        "id": "izTlJqAKOC8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Input Image:**\n",
        "\n",
        "    - The process starts with an input image.\n",
        "\n",
        "2. **Region Proposal:**\n",
        "\n",
        "    - Use Selective Search to generate around 2000 region proposals. Each proposal is a potential region that might contain an object.\n",
        "\n",
        "3. **Warping Regions:**\n",
        "\n",
        "    - Each region proposal is resized to a fixed size required by the CNN (e.g., 227x227 pixels).\n",
        "\n",
        "4. **CNN Feature Extraction:**\n",
        "\n",
        "    - Pass each resized region proposal through a CNN. The CNN extracts high-level features from the region. The output from a fully connected layer of the CNN is used as the feature vector.\n",
        "\n",
        "5. **Classification with SVM:**\n",
        "\n",
        "    - Each feature vector is classified using class-specific linear SVMs. Each SVM is trained to detect a specific class, and there is an additional SVM to detect the background.\n",
        "\n",
        "6. **Bounding Box Regression:**\n",
        "\n",
        "    - For each classified region, a bounding box regressor adjusts the proposed bounding box coordinates to better fit the object.\n"
      ],
      "metadata": {
        "id": "AlCuQBICOWQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "U897-NGnYhHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning as subset of ML\n",
        "\n",
        "from IPython import display\n",
        "display.Image(\"data/images/DL_01_Intro-01-DL-subset-of-ML.jpg\")"
      ],
      "metadata": {
        "id": "juNAxVBFg7sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rainbow](https://github.com/ancilcleetus/My-Learning-Journey/assets/25684256/839c3524-2a1d-4779-85a0-83c562e1e5e5)"
      ],
      "metadata": {
        "id": "qqv0L0R9dyKJ"
      }
    }
  ]
}