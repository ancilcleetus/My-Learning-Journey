{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Basic Concepts"
      ],
      "metadata": {
        "id": "oAsAd7cxd-7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Evolution of CNNs\n",
        "\n",
        "Even though Traditional ML Algorithms performed well on tabular data, their performance was poor on Image Processing tasks. 2D Images were flattened to 1D vector before input to Traditional ML Algorithms. Since images represent information using local features (where pixels that form local relationships represent a particular feature of the image), flattening 2D images to 1D vector does not properly extract the information from the image.\n",
        "\n",
        "Research on visual cortex of cats led to the discovery of CNNs (Convolutional Neural Nets). In CNNs, the 2D image is passed to multiple Convolutional layers. Each Convolutional layer has multiple kernels / filters. These kernels capture different features from the image such as edges, shapes, depth, color etc. After passing through multiple layers and extracting enough information to do an Image Processing task such as Image Classification, we have a set of feature maps. All of these 2D feature maps are flattened to create a 1D vector called an image embedding. A fully connnected neural network (Multilayer Perceptron) can be trained on these image embeddings to perform Image Classification."
      ],
      "metadata": {
        "id": "YaGCwHdZnnI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Padding and Stride\n",
        "1. Padding: Preserves spatial resolution of image over multiple layers\n",
        "2. Stride: Reduces the number of operations in the convolution operation => Reduction of Computational Complexity"
      ],
      "metadata": {
        "id": "3FMv7lrXgQW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. Calculations for image size after convolution operation (Input image size $n \\times n$, Kernel size $k \\times k$, Padding $p$, Stride $s$)\n",
        "*   No Padding, Stride = 1 => $(n - k + 1) \\times (n - k + 1)$\n",
        "*   Padding = $p$, Stride = 1 => $(n + 2p - k + 1) \\times (n + 2p - k + 1)$\n",
        "*   No Padding, Stride = $s$ => $(\\frac{n - k}{s} + 1) \\times (\\frac{n - k}{s} + 1)$\n",
        "*   Padding = $p$, Stride = $s$ => $(\\frac{n + 2p - k}{s} + 1) \\times (\\frac{n + 2p - k}{s} + 1)$\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** If the expression $\\frac{n + 2p - k}{s}$ results in a fractional number, you typically have two common options for handling this situation in Convolutional Neural Networks:\n",
        "1. Floor Division: Round down the result of the division to the nearest integer.\n",
        "2. Ceiling Division: Round up the result of the division to the nearest integer.\n",
        "\n",
        "The choice between these two options depends on the specific implementation and the desired behavior. In most deep learning frameworks, such as PyTorch or TensorFlow, the default behavior is floor division. However, you might find cases where ceiling division is used depending on the specific needs of the model or the layer."
      ],
      "metadata": {
        "id": "NZoQWoFzeTr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pooling\n",
        "1. Max Pooling: Maximum pixel value\n",
        "2. Average Pooling: Average of pixel values"
      ],
      "metadata": {
        "id": "cW51gVPcrPJI"
      }
    }
  ]
}